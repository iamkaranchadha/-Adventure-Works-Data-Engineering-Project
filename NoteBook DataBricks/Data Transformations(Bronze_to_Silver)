Importing the libraries

from pyspark.sql.functions import *
from pyspark.sql.types import *

Data Reading

df_customer = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Customers")

df_calender = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Calendar")


df_product_categories = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Product_Categories")


df_products = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Products")

df_returns = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Returns")

df_sales = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Sales*")

df_territories = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Territories")

df_subcategories = spark.read.format("csv").option("header",True)\
    .option("inferSchema",True)\
    .load("abfss://bronze@awstoragedatalakekaran.dfs.core.windows.net/Product_Subcategories")


Data Transformation and Data Writing

Calender

df_calender = df_calender.withColumn("Month",month(col("Date")))\
            .withColumn("Year",year(col("Date")))

df_calender.write.format("Parquet")\
          .mode("append")\
          .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Calendar")\
          .save()


Customers

#df_customer.withColumn("Full_Name",concat(col("Prefix"),lit(' '),col("FirstName"),lit(' '),col("LastName"))).display()

df_customer = df_customer.withColumn("FullName",concat_ws(' ',col("Prefix"),col("FirstName"),col("LastName")))

df_customer.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Customer")\
            .save()

Subcategory

df_subcategories.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Subcategories")\
            .save()

Products

df_products = df_products.withColumn("ProductSKU",split(col("ProductSKU"),"-")[0])\
            .withColumn("ProductName",split(col("ProductName")," ")[0])

df_products.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Products")\
            .save()

Returns

df_returns.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Returns")\
            .save()

Territories

df_territories.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Territories")\
            .save()

Product Categories

df_product_categories.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Product_Categories")\
            .save()

Sales

df_sales = df_sales.withColumn("StockDate", to_timestamp(col("StockDate")))\
        .withColumn("OrderNumber",regexp_replace(col("OrderNumber"),'S','T'))

df_sales.write.format("Parquet")\
            .mode("append")\
            .option("Path","abfss://silver@awstoragedatalakekaran.dfs.core.windows.net/AdventureWorks_Sales")\
            .save()

df_sales.groupBy("OrderDate").agg(count(col("OrderNumber")).alias("TotalOrders")).display()






